---
title: "Kickstarter Analysis"
subtitle: "11/20/2020"
author: "The Laureates: Farzeen Najam, Olivia Olsher, Vincent Liu, Emile Therrien"
output: pdf_document
---

# Introduction
Have you ever had an ambitious idea but did not have resources to pursue it? Kickstarter is a crowdfunding platform for creators who need support for their projects. Since launching in 2009, 19 million people have pledged to back up projects, and nearly 190,000 projects have been successfully funded.
 
However, many more projects failed to reach their goals, and our group is interested in analyzing what made projects succeed and fail. The dataset [Kickstarter Projects](https://www.kaggle.com/kemical/kickstarter-projects) comes from Kaggle, which contains Kickstarter projects up until January 2018.
 
We will be exploring which variables influence the success of a Kickstarter project by observing which types of projects are more likely to be funded. Our questions include:

* Does the amount of money a project asks for influence it’s chance of success?
* Does the category of project influence it’s chance of success?

Our hypotheses include:

* The more money the project asks for, the less successful it will be in terms of getting funding.
* The project category is associated with the success rate, and “Technology” will be the most likely funded type of projects compared to others.

# Data Description

```{r file-glimpse, eval=TRUE, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)
library(broom)

kickstarter <- read_csv("data/ks-projects-201801.csv")
glimpse(kickstarter)
```

This data set contains 15 variables and 378,661 observations, where each observation is one kickstarter project.

The categorical variables include the name of each project, the category of each project (music, narrative film, restaurant, etc.), a broader category of each (food, film, publishing, etc.), the crowdsourcing currency, the state of each project (failed, successful, or cancelled), and the country of origin for each project.

The numerical data are the project’s ID number, the monetary goal for each, the money pledged to each project, how many backers of each project; there are three numerical variables that are not self-explanatory, usd_pledged: conversion in US dollars of the pledged column (conversion done by kickstarter), usd_pledge_real: conversion in US dollars of the pledged column (conversion from Fixer.io API), and usd_goal_real: conversion in US dollars of the goal column (conversion from Fixer.io API).

There are also two date columns, one for the project launch and the other for the crowdsourcing deadline.

The data were collected from Kickstarter Platform likely using web scraping methods on their own site, to be used by data scientists to model whether or not a project will be successful or not when it is launched.

# Explorative Data Analysis

**TODO**: In the exploratory data analysis section, it would be useful to add a bar chart for the counts of the project states to visually represent that summary

## Overview of project state:

```{r state-analysis, warning=FALSE, message=FALSE, echo=FALSE}
kickstarter_state_count <- kickstarter %>%
  group_by(state) %>%
  count() %>%
  arrange(desc(n))

ggplot(data = kickstarter_state_count,
       aes(x=state, y=n)) +
  geom_bar(stat = "identity") +
  labs(x = "Project State",
       y = "Count",
       title = "Distribution of project states",
       subtitle = "More projects fail than those that succeed") +
  theme_bw()

kickstarter_success_rate = kickstarter %>%
  filter(state == "successful") %>%
  summarize("project success rate" = n()/nrow(kickstarter))

kickstarter_state_count
kickstarter_success_rate
```

## Overview of pledged and goal amount in USD:

```{r pledged-and-goal-overview, echo=FALSE,warning=FALSE, message=FALSE, echo=FALSE}
overview_usd_pledged_real <- kickstarter %>%
  summarize(mean = mean(usd_pledged_real),
            median = median(usd_pledged_real),
            sd = sd(usd_pledged_real)) %>% 
  mutate(type = "pledged")

overview_usd_goal_real <- kickstarter %>%
  summarize(
    mean = mean(usd_goal_real),
    median = median(usd_goal_real),
    sd = sd(usd_goal_real))%>% 
  mutate(type = "goal")

overview_usd_pledged_real
overview_usd_goal_real

pledged_goals <- full_join(overview_usd_pledged_real, overview_usd_goal_real,
                          by = NULL)

ggplot(data = pledged_goals,
       aes(x = type, y = mean, fill = type)) +
  scale_fill_viridis_d() +
  geom_col() +
  labs(title = "Mean Amount of Goal vs. Pledged Amount",
       subtitle = "Pledged amount is usually much less than the goal amount") +
  theme_bw()
```

# Methodology

**TODO**:

* For the methodology section, it is also essential to justify the statistical methods that you will be using in your analyses to answer your research question, so that researchers go into the results section with no doubts about the appropriateness of your choices.
* How do we sample and what should the size of sample for the bootstraps be?

# Data Analysis

## Project Goal Amount and Success

*Claim*: The more money the project asks for (project goal), the less successful it will be in terms of getting funding.

**TODO**: 

* add some context here why we examine this relationship
* you could explain/justify the specific variables you chose to include such as “used_goal_real_tier”--what does this variable mean and how does the classification into tiers with your mutated variable relate to the larger analysis on goal v. success rate? This will make it easier for the reader to follow along and allow you to have methods with enough detail such that they can be reproducible. Explain how tiers were defined. rationale.

Create a new data frame with projects that are no longer live:

```{r exclude-ongoing-projects,warning=FALSE, message=FALSE, echo=FALSE}
# Exclude ongoing projects
kickstarter_not_live <- kickstarter %>%
  filter(state != "live")
```

Create a new variable named usd_goal_real_tier to classify usd_goal_real into tiers:




```{r mutate-goal-tiers,warning=FALSE, message=FALSE, echo=FALSE}

# perhaps need a better way to categorize values in this column
kickstarter_not_live <- kickstarter_not_live %>%
  mutate(usd_goal_real_tier = case_when(
    usd_goal_real < 1000 ~ 1,
    usd_goal_real >= 1000 & usd_goal_real < 5000 ~ 2,
    usd_goal_real >= 5000 & usd_goal_real < 10000 ~ 3,
    usd_goal_real >= 10000 & usd_goal_real < 20000 ~ 4,
    usd_goal_real >= 20000 & usd_goal_real < 100000 ~ 5,
    usd_goal_real >= 100000 & usd_goal_real < 500000 ~ 6,
    usd_goal_real >= 500000 ~ 7,
  ))

chart<- kickstarter_not_live %>%
  group_by(usd_goal_real_tier) %>%
  summarize(numbers = n())

chart

ggplot(data = chart, mapping = aes(x = usd_goal_real_tier, y = numbers, 
                                  fill = as.factor(usd_goal_real_tier))) +
  geom_col() +
  scale_fill_viridis_d()+
  labs(title = "Tier 2 has the most amount of projects",
       x = "Tier number", y = "Count of projects") +
  theme_minimal() + 
  theme(legend.position = "none")
```

Create a new variable for success state

```{r mutate-success-state,warning=FALSE, message=FALSE, echo=FALSE}
kickstarter_not_live <- kickstarter_not_live %>%
  mutate(success_state = if_else(state == "successful", 1, 0))
```

*Hypotheses*:

$H_0$: $S_{less-money}$ $\le$ $S_{more-money}$
$H_1$: $S_{less-money}$ > $S_{more-money}$

**TODO**:

* “proportion of people who successful with low money goal." was initially difficult to follow/understand exactly what you are trying to test.
* in the analysis paragraphs following the tests, including the actual p-value found and the alpha level it was tested against is information that is necessary. This was present in some tests, but was missing in the project goal amount and success section. As an example of how this specifically could be improved, in the project goal amount and success section, you may wish to support your claim of “our p-value is less than our alpha value” with the actual p-value you calculate and the alpha value you are testing in. Additionally, when there is sufficient evidence to reject the null hypothesis, make a statement about how this means there is sufficient evidence to claim that the alternative is true. This sentence will help bridge the two conclusions made. In the analysis for the project category and success section, it may be clearer to use a word other than “main category” in the hypothesis test conclusion (i.e. say project of category or something more specific in the context of the research than simply what the variable is named in the dataset).
* Each bootstrap analysis is only performed with the number of simulations being set to 500. However, the more simulations there are, the more accurate the prediction of the relationship in the data will be. Therefore, any simulation-based methods used to evaluate hypotheses of interest should be set to at least 1000 simulations, instead.

* explain why you chose certain variables and how you then incorporated those into your hypo test
* express the hypotheses in notation and then explain the notation's meaning.

$H_0$:proportion of people who successful with low money goal - proportion of people who successful with high money <= 0
$H_1$: proportion of people who successful with low money goal - proportion of people who successful with high money > 0 

$\alpha$ = 0.05

```{r money-eval,warning=FALSE, message=FALSE, echo=FALSE}
set.seed(1)
kick1 <- kickstarter_not_live %>% 
  filter(usd_goal_real_tier == 6 | usd_goal_real_tier == 5 | 
        usd_goal_real_tier == 4 | usd_goal_real_tier == 7)

kick2 <- kickstarter_not_live %>% 
  filter(usd_goal_real_tier == 1 | usd_goal_real_tier == 2 | 
        usd_goal_real_tier == 3 | usd_goal_real_tier == 4)
     
t.test(kick1$usd_goal_real_tier, mu = 0, alternative = "greater", conf.level = 0.95)
```

**TODO**:

* State the p-value and alpha value explicitly here.
* Currently the statement is repeatitive because you said twice "we reject our null hypothesis that". 

Since our p-value is less than our alpha value, we reject our null hypothesis that the difference in the proportion of projects with less money as goal and proportion of projects with more money as goal is less than or equal to 0. This means we reject the null hypothesis that success rate for projects with bigger money is equal or higher than projects with lower money.

## Project Category and Success

### Relationship between Project Category and Success

*Question*: Does the category of project influence it’s chance of success?

**TODO**

* how not to hard code sum in kickstarter_success_ratio pipeline
* limitations: possible crossover in the main_categories that we cannot screen
for
* (from feedback) In the project category and success and goal amount and success categories, this was already mentioned as notes, but there are sum numbers hard coded into the bootstrapping, which make the code not replicable if the sample size were changed, for instance. This should be addressed.
* how to weight each bar graph the same to show proportionality
between main categories?
* exclude the live data (and provide an explanation) when calculating kickstater_success_ratios
* need to see what category is most likely to be funded (Emile wrote this a week ago... not sure what it means now)

```{r category-success,warning=FALSE, message=FALSE, echo=FALSE}

kickstart_success <- kickstarter_not_live %>% 
  mutate(
    project_funding_ratio = pledged/goal,
    success = case_when(
      project_funding_ratio >= 1 ~ 1,
      project_funding_ratio < 1 ~ 0
    )
  )

kickstater_success_ratios = kickstart_success %>% 
  group_by(main_category, success) %>% 
  count(success) 

kickstater_success_ratios <- kickstarter_not_live %>% 
  group_by(main_category, success_state) %>% 
  count(success_state) %>% 

  group_by(main_category) %>% 
  mutate(
    prop = n/sum(n),
    plot_success = case_when(
      success_state == 1 ~ "Success",
      success_state == 0 ~ "Others"
    )
  )

kickstater_success_ratios

ggplot(data = kickstater_success_ratios,
       aes(x = plot_success, y = prop, fill = main_category)) +
  ylim(0, 1) +
  facet_wrap(. ~ main_category) +
  geom_col() +
  theme(legend.position = "none") +
  labs(x = "Success",
       y = "Proportion of successful projects",


       title = "Most Categories Were Not Successful on Average",
       subtitle = "Faceted by Main Category")

#title = "Comics, Dance, Music, and Theater categories had a success ratio greater than 1")+

       title = "Successful vs. Other Projects, grouped by category",
       subtitle = "Success ratio of Comics, Dance, Music, and Theater categories > 1") +

  scale_fill_viridis_d()


```

main_category vs. success

$H_0$: There is no relationship between main_category and success.

$H_1$: There is a relationship between main_category and success. 

Where the $alpha/$ = 0.05

```{r chi-square-main_category,warning=FALSE, message=FALSE, echo=FALSE}
chisq.test(table(kickstart_success$main_category, kickstart_success$success))
```

**TODO**:

- Olivia: discussion on this chi-squared piece 

* state the p-value here
* describe and justify why you ran a chi-squared test and what information this test will provide you in context of supporting your larger question/hypotheses. There could also be greater explanation of the individual steps you took before completing the overall chi-squared test
* when there is sufficient evidence to reject the null hypothesis, make a statement about how this means there is sufficient evidence to claim that the alternative is true. This sentence will help bridge the two conclusions made. In the analysis for the project category and success section, it may be clearer to use a word other than “main category” in the hypothesis test conclusion (i.e. say project of category or something more specific in the context of the research than simply what the variable is named in the dataset). 
* Interpretation of chi-square test could follow a format like this: "Our test statistic was 19624, which has a chi-square distribution with 6 degree of freedom under $H_0$. This corresponds to a p-value less than 2.2e-16. So our decision is to reject $H_0$, and there is sufficient evidence that there is a relationship between a project's monetary goal and a project's state of success."

Given that the p-value is less than $alpha/$ = 0.05, we can reject the null hypothesis. Thus, there is sufficient evidence to suggest that there is a relationship between main category and success.

### Success Rate of Technology Category vs. Others

*Claim*: The category “Technology” will be the most likely funded type of projects.

$H_0$: $p_{s-tech}$ $\le$ $p_{s-other}$
$H_1$: $p_{s-tech}$ > $p_{s-other}$

**TODO**:

* Provide an explanation of hypotheses and define an alpha value
* Each bootstrap analysis is only performed with the number of simulations being set to 500. However, the more simulations there are, the more accurate the prediction of the relationship in the data will be. Therefore, any simulation-based methods used to evaluate hypotheses of interest should be set to at least 1000 simulations, instead.
* For the project category and success section, although the approach and model of analysis are clear, we believe that a p-value of 1 may be unlikely. In your histogram, the observed difference line is so far from the simulated null distribution that observing that proportion under the null distribution seems very unlikely, at least a probability less than 1. Regardless, in order to make the model more clear, that last histogram should be labeled a lot better, with a title about whether this rejects or fails to reject the null, the number of simulations used for bootstrapping, and what the red line represents.

```{r simulation-technology,warning=FALSE, message=FALSE, echo=FALSE}
set.seed(1)

kickstart_boot = kickstart_success %>% 
  mutate(
    TECH = case_when(
      main_category == "Technology" ~ 1,
      main_category != "Technology" ~ 0
    )
  )

kickstart_boot
         
obs_diff = kickstart_boot %>% 
  group_by(TECH) %>% 
  count(success) %>% 
  mutate(prop = n/sum(n)) %>% 
  filter(success == "achieved") %>% 
  select(TECH, prop)
obs_diff

diff = obs_diff[2,2] - obs_diff[1,2] #take second row and second column - ...

diff

tech = kickstart_boot %>% 
  filter(TECH == "1")
other = kickstart_boot %>% 

  filter(TECH != "TECH")

boot_samp <- numeric(500)

for(i in 1:500){
  boot_tech <- tech %>% 
    slice(sample(1:nrow(tech), replace = T)) %>% 
    count(success) %>% 
    mutate(prop = n/sum(n)) %>% 
    select(prop) %>% 
    slice(1) %>%
    pull()
  boot_other<- other %>% 
    slice(sample(1:nrow(other), replace = T)) %>% 
    count(success) %>% 
    mutate(prop = n/sum(n)) %>% 
    select(prop) %>% 
    slice(1) %>%
    pull()
  
  boot_samp[i] <- boot_tech - boot_other
}

#mean of bootstrap samples:
mean_boot = mean(boot_samp)
boot_samp = tibble(boot_samp)

boot_samp <- boot_samp %>% 
  mutate(centered = boot_samp + abs(mean_boot))
       
boot_samp %>% 
  mutate(extreme = if_else(centered > abs(diff), 0, 1)
  ) %>% 
  summarize(p_val = mean(extreme))

ggplot(data = boot_samp, aes(x = centered)) + 
  geom_histogram(color = "darkblue", fill = "skyblue") +
  labs(x = "centered means", 
       y = "count", 
       title = "Bootstrap Distribution of Proportions of Success") +
  geom_vline(xintercept = diff$prop, color = "red")

  filter(TECH == 0)

t.test(kickstart_boot$TECH, mu = 0, alternative = "less")
```


We have a p-value of 1, which means there is not sufficient evidence at the $\alpha$ = 0.05 level to reject the null hypothesis that the proportion of success for main categories other than Technology is the same or greater than the proportion of sucess for Technology. 

## Project Goal Amount and Pledge Amount

Here we used a linear model to model success. Specifically, we wanted to see how the project's main category leads to differences in the odds of success. We can't model goal or pledged amounts due to the sheer number of outliers in the dataset. There are some projects asking for a penny in USD and others asking for upwards of $100,000,000.

We used Technology as our reference level to maintain consistency throughout the project.

```{r models,warning=FALSE, message=FALSE, echo=FALSE}
# change reference to Tech
kickstart_success$main_category <- factor(
  kickstart_success$main_category, 
  levels = c("Technology", 
             "Art", 
             "Comics", 
             "Crafts",
             "Dance", 
             "Design", 
             "Fashion",
             "Film & Video",
             "Food", 
             "Games", 
             "Journalism", 
             "Music",
             "Photography",
             "Publishing",
             "Theater")
  )

# glm model for success based on main cat
success_mod = glm(success ~ main_category,
                  data = kickstart_success, family = "binomial")

tidy(success_mod)
```


Relative to Technology, the most likely funded project category is Dance. The odds of success for Dance is 6.374285
times the odds of success for Technology. Furthermore, all else being equal, the estimated probability of success 
for the Dance category is 0.62, whereas for Technology the probability of success is 0.21. There is sufficient
evidence based on our model to suggest that Technology is not the most readily successful project type.
s

Relative to Technology, the most likely funded project category is Dance. The odds of success for Dance is 6.374285 times the odds of success for Technology. Furthermore, all else being equal, the estimated probability of success for the Dance category is 0.62, whereas for Technology the probability of success is 0.21. There is sufficient evidence based on our model to suggest that Technology is not the most readily successful project type.


# Discussion


**TODO**: Furthermore, the entire discussion section is missing, as there is no overall summary of what all of the hypothesis tests have shown in the context of the research question, along with the specific p-values that support these conclusions. To make your results and conclusions stronger, you should also critique your own methods and provide suggestions for improving your analysis, as showing possible faults in reliability and validity of your data and the appropriateness of the statistical analyses helps support your positions as researchers and knowledge of the data. To add onto conclusions that you write, you should also discuss what you would do next if you were going to continue work on the project to show where your analyses could have gone farther.
